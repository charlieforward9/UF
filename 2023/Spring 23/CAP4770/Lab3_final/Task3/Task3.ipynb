{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JfDdJuTV0ziD"
   },
   "source": [
    "# Task3 Deep Learning for Streamline Segmentation from Earth imagery\n",
    "<font color=\"red\">Instructions: please fill in marked missing codes and answer required questions. </font> \n",
    "## Part 1: Loading Data\n",
    "There are six data files in the folder:\n",
    ">X_test.npy   X_val.npy   Y_train.npy  \n",
    "X_train.npy  Y_test.npy  Y_val.npy\n",
    "\n",
    "They are corresponding to the feature images X and label images Y in training set, validation set, and test set.\n",
    "\n",
    "In the feature images, there are 7 channels, including:\n",
    "\n",
    "**Red, Green, Blue, NIR (near infrared), DEM (digital elementation), lidar intensity, Slope.**\n",
    "\n",
    "If you want to use Google Colab and request its computing resources, please download the provided dataset and upload it to your Google Drive folder. Then mount the Google Drive folder to your Colab virtual machine. Please refer to the following link for details: https://colab.research.google.com/notebooks/io.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ukoZ6e080ziG",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os, sys, time,tempfile, random, csv\n",
    "import tensorflow as tf\n",
    "import keras \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import concatenate\n",
    "\n",
    "import keras.backend as K\n",
    "import keras.metrics as kmetrics\n",
    "from keras.layers import UpSampling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers.core import SpatialDropout2D, Activation\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Dropout, Lambda\n",
    "from keras.models import Model, save_model, load_model\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rUwflOgdSiX5",
    "outputId": "966661bb-4340-446d-cd8b-ce73d7e12cdc"
   },
   "outputs": [],
   "source": [
    "### Loading Tensors\n",
    "X_train = np.load('X_train.npy')\n",
    "Y_train = np.load('Y_train.npy')\n",
    "\n",
    "X_val = np.load('X_val.npy')\n",
    "Y_val = np.load('Y_val.npy')\n",
    "\n",
    "X_test = np.load('X_test.npy')\n",
    "Y_test = np.load('Y_test.npy')\n",
    "\n",
    "print(\"Successfully loaded tensors.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iGXIOE9LZtBo"
   },
   "source": [
    "PLEASE ANSWER THE QUESTIONS BELOW: \n",
    "1. How many training, validation, and test images, respectively?\n",
    "2. What is the size (width, height) of each image?\n",
    "3. How many channels are there in each feature image?\n",
    "\n",
    "You can answer above questions with variables defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wxF-jqeq1jtm",
    "outputId": "38274560-e5b9-4d14-e46e-6aa7c06284ec"
   },
   "outputs": [],
   "source": [
    "# print out your answers below\n",
    "\n",
    "print('The number of training, validation, and test images is', )\n",
    "\n",
    "print('The size of each image is: ', )\n",
    "\n",
    "print('The channels number in each image is: ', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 653
    },
    "id": "zaeYkNXvCHE4",
    "outputId": "f3a982ad-7c1e-44a7-89be-a07dbf7278ea"
   },
   "outputs": [],
   "source": [
    "# randomly sample a number of training images\n",
    "# plot their RGB features and DEM (digital elemention model) feature, and ground truth pixel labels\n",
    "# note that some image patches may not have class 1 (stream) pixels (these are image windows without a stream passing through)\n",
    "sample_count = 3\n",
    "\n",
    "for i in range(sample_count):\n",
    "    t_choice = np.random.randint(0, len(X_train)-1)\n",
    "    \n",
    "    y_tile = np.squeeze(Y_train[t_choice])\n",
    "    \n",
    "    x_tile = X_train[t_choice]\n",
    "    \n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(ncols=3, figsize=(9,4))\n",
    "    \n",
    "    print('Sample {}'.format(t_choice))\n",
    "    ax1.imshow(x_tile[:,:,0:3])\n",
    "    ax1.set_title('Train Image {}'.format(t_choice))\n",
    "        \n",
    "    ax2.imshow(x_tile[:,:,4])\n",
    "    ax2.set_title('Train DEM {}'.format(t_choice))\n",
    "    \n",
    "    ax3.imshow(y_tile)\n",
    "    ax3.set_title('Train Label {}'.format(t_choice))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GQHvNK1y0ziI"
   },
   "source": [
    "## Part 2: Model Construction\n",
    "\n",
    "This part defines the U-Net model architecture, defines the **negative Dice Coefficient** as the loss function, and defines several evaluation metric functions, e.g., precision, recall, F1-score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m-QkdQkuWQZI"
   },
   "source": [
    "Below is the U-Net model architecture used in Lab 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OLEXuxtE0ziJ"
   },
   "outputs": [],
   "source": [
    "###U-Net model architecture\n",
    "############################\n",
    "\n",
    "INPUT_CHANNELS = 7\n",
    "OUTPUT_CHANNELS = 1 \n",
    "\n",
    "def double_conv_layer(x, size, std_init, dropout=0.2):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        axis = 1\n",
    "    else:\n",
    "        axis = 3\n",
    "        \n",
    "    # TODO: Implement double convolutional layer (Conv2D) below with 3*3 convolutional kernel, \n",
    "    # padding to make the output size be the same as the input size, and select ReLU as the activation function (Activation).\n",
    "    # Note: Consecutive 2 convolutional layers with no pooling.\n",
    "    conv_1 = \n",
    "    conv_1_activated = \n",
    "    conv_2 = \n",
    "    conv_2_activated = \n",
    "    # TODO Ends\n",
    "    \n",
    "    if dropout > 0:\n",
    "        conv = SpatialDropout2D(dropout)(conv_2_activated)\n",
    "    return conv\n",
    "\n",
    "def UNET_7_224_dropout(dropout_val=0.2, std_init=None):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        inputs = Input((INPUT_CHANNELS, 224, 224))\n",
    "        axis = 1\n",
    "    else:\n",
    "        inputs = Input((224, 224, INPUT_CHANNELS))\n",
    "        axis = 3\n",
    "    filters = 32\n",
    "\n",
    "    conv_224 = double_conv_layer(inputs, filters, std_init)\n",
    "    pool_112 = MaxPooling2D(pool_size=(2, 2))(conv_224)\n",
    "\n",
    "    conv_112 = double_conv_layer(pool_112, 2*filters, std_init)\n",
    "    pool_56 = MaxPooling2D(pool_size=(2, 2))(conv_112)\n",
    "\n",
    "    conv_56 = double_conv_layer(pool_56, 4*filters, std_init)\n",
    "    pool_28 = MaxPooling2D(pool_size=(2, 2))(conv_56)\n",
    "\n",
    "    conv_28 = double_conv_layer(pool_28, 8*filters, std_init)\n",
    "    pool_14 = MaxPooling2D(pool_size=(2, 2))(conv_28)\n",
    "\n",
    "    conv_14 = double_conv_layer(pool_14, 16*filters, std_init)\n",
    "    pool_7 = MaxPooling2D(pool_size=(2, 2))(conv_14)\n",
    "\n",
    "    conv_7 = double_conv_layer(pool_7, 32*filters, std_init)\n",
    "\n",
    "    up_14 = concatenate([UpSampling2D(size=(2, 2))(conv_7), conv_14], axis=axis)\n",
    "    up_conv_14 = double_conv_layer(up_14, 16*filters, std_init,dropout_val)\n",
    "\n",
    "    up_28 = concatenate([UpSampling2D(size=(2, 2))(up_conv_14), conv_28], axis=axis)\n",
    "    up_conv_28 = double_conv_layer(up_28, 8*filters, std_init,dropout_val)\n",
    "\n",
    "    up_56 = concatenate([UpSampling2D(size=(2, 2))(up_conv_28), conv_56], axis=axis)\n",
    "    up_conv_56 = double_conv_layer(up_56, 4*filters, std_init,dropout_val)\n",
    "\n",
    "    up_112 = concatenate([UpSampling2D(size=(2, 2))(up_conv_56), conv_112], axis=axis)\n",
    "    up_conv_112 = double_conv_layer(up_112, 2*filters, std_init,dropout_val)\n",
    "\n",
    "    up_224 = concatenate([UpSampling2D(size=(2, 2))(up_conv_112), conv_224], axis=axis)\n",
    "    up_conv_224 = double_conv_layer(up_224, filters, std_init, dropout_val)\n",
    "\n",
    "    conv_final = Conv2D(OUTPUT_CHANNELS, (1, 1), kernel_initializer=std_init)(up_conv_224)\n",
    "    \n",
    "    # TODO: Choose an appropriate activation function.\n",
    "    conv_final = Activation(' ')(conv_final)\n",
    "    # TODO Ends\n",
    "\n",
    "    model = Model(inputs, conv_final, name=\"UNET_7_224\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0WXBw6YqbGoW"
   },
   "source": [
    "PLEASE ANSWER THE QUESTIONS BELOW: \n",
    "1. How many downsample (MaxPooling2D) operations and upsampling (UpSampling2D) operations in total, respectively?\n",
    "2. How many convolution (Conv2D) operations in total?\n",
    "3. What is the non-linear activation function used for the final class layer, sigmoid or softmax? Why is this function chosen (but not the other)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H2Vfl90ubXnG",
    "outputId": "4188431b-d74d-426f-a8a2-5e6740456c24"
   },
   "outputs": [],
   "source": [
    "# My answer is:\n",
    "ans = '''\n",
    "1. xxx \\n\n",
    "2. xxx \\n\n",
    "3. xxx\n",
    "'''\n",
    "\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "igbbKiwiXPEQ"
   },
   "source": [
    "**Below is the loss function, i.e., negative dice coefficience.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mQFdR9AIXOP0"
   },
   "outputs": [],
   "source": [
    "### Loss function, negative dice coefficient\n",
    "#################\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    \"\"\" Soft label dice coefficient measure. \"\"\"\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2.0 * intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1.0)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return - dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "opDFSe9o0ziO"
   },
   "source": [
    "### Part 3: Model Training and Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "id": "0D6EJPP_0ziO",
    "outputId": "91c8b9a1-cb8c-42ed-fb1a-904e8fb92e98",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Model Training\n",
    "num_epochs = 30\n",
    "batch_size = 32\n",
    "learn_rate = 0.01\n",
    "\n",
    "model = UNET_7_224_dropout(dropout_val=0.2)\n",
    "model.compile(optimizer=Adam(learning_rate=learn_rate, epsilon=1e-8, weight_decay=1e-5), loss=dice_coef_loss, metrics=['accuracy'])\n",
    "\n",
    "my_callbacks = [ \n",
    "      ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5, min_deta=0.00001, verbose=0, mode='min'),\n",
    "      EarlyStopping(monitor='val_loss', patience=20, verbose=0)]\n",
    "\n",
    "# TODO: Complete the fit function with parameters (num_epochs, batch_size, my_callbacks) defined above.\n",
    "# Note: The vairable \"results\" will store information about the training process.\n",
    "# Place your code here (1 line)\n",
    "results = \n",
    "# TODO Ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rNW9TA8I0HXw",
    "outputId": "e5c47d62-1579-47f0-fa89-a9f9d459dfdb"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s0nUrfjTqir2"
   },
   "source": [
    "Plot training and validation curves\n",
    "\n",
    "**Hint**: the training process has quite some randomness. If your curve shape does not look good, you can re-run the training codes and check again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "5mPQqLRJ0VGR",
    "outputId": "25be3171-4d96-478e-8609-8ea59c164368"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(results.history['loss'],label='training loss')\n",
    "plt.plot(results.history['val_loss'],label='validation loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLEASE ANSWER THE QUESTIONS BELOW: Based on the figure above, has the loss function converged? Do you think it's necessary to continue training? Please explain your reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = '''\n",
    "xxx\n",
    "'''\n",
    "\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z-Fx9vPZY4Tn"
   },
   "source": [
    "### Evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g1yw8FH3Xb4H"
   },
   "source": [
    "Below is the evaluation metrics (precision, recall, and f1-score) on Y predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nNeU3U7QXcIu"
   },
   "outputs": [],
   "source": [
    "### Model Metrics\n",
    "#################\n",
    "\"\"\" y_true is binary with shape [xx,224,224,1] and y_pred is probabilities with the same shape \"\"\"\n",
    "\n",
    "def f1_score(y_true, y_pred): \n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2 * (precision * recall) / (precision + recall + K.epsilon())\n",
    "    return f1_val\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\" Get precision \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\" Get recall \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0GUeJD360ziP",
    "outputId": "9efee4bf-dd36-443a-95d6-7615ec80afe0"
   },
   "outputs": [],
   "source": [
    "\"\"\" Evaluate Model Preformance \"\"\"\n",
    "print(\"Preformance:\")\n",
    "\n",
    "# TODO: implement the codes for evaluation below.\n",
    "# Training Performance\n",
    "train_precision = \n",
    "train_recall = \n",
    "train_f1 = \n",
    "print(\"Training precision: {:.2f}\\n\".format( train_precision ) , \n",
    "      \"Training Recall: {:.2f}\\n\".format(train_recall) , \n",
    "      \"Training F1 Score: {:.2f}\\n\".format(train_f1) )\n",
    "\n",
    "# Validation Performance\n",
    "val_precision = \n",
    "val_recall = \n",
    "val_f1 = \n",
    "print(\"Validation precision: {:.2f}\\n \".format(val_precision) , \n",
    "      \"Validation Recall: {:.2f}\\n\".format(val_recall) , \n",
    "      \"Validation F1 Score: {:.2f}\\n\".format(val_f1) )\n",
    "\n",
    "# Test Performance\n",
    "test_precision = \n",
    "test_recall =  \n",
    "test_f1 = \n",
    "print(\"Test precision: {:.2f}\\n \".format(test_precision) , \n",
    "      \"Test Recall: {:.2f}\\n\".format(test_recall), \n",
    "      \"Test F1 Score: {:.2f}\\n\".format(test_f1))\n",
    "\n",
    "# TODO Ends\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pu5Cm1DeYk_n"
   },
   "source": [
    "### Result Interpretation\n",
    "\n",
    "Visualize the prediction results and compare them with feature images and ground truth class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 689
    },
    "id": "AeLqBpa8Ez8L",
    "outputId": "be4a184e-5fd0-4a62-81e7-1b254d43e78b"
   },
   "outputs": [],
   "source": [
    "Y_pred = np.copy(model.predict(X_test))\n",
    "sample_count = 3\n",
    "for i in range(sample_count):\n",
    "    t_choice = np.random.randint(0, len(X_test)-1)\n",
    "    \n",
    "    y_tile = np.squeeze(Y_test[t_choice])\n",
    "\n",
    "    y_pred_i = np.squeeze(Y_pred[t_choice])\n",
    "\n",
    "    y_pred_i = np.where(y_pred_i>=0.5, 1, 0)\n",
    "    \n",
    "    x_tile = X_test[t_choice]\n",
    "    \n",
    "    fig, (ax1, ax2, ax3, ax4) = plt.subplots(ncols=4, figsize=(9,4))\n",
    "    \n",
    "    print('\\n\\n\\nSample {}'.format(t_choice))\n",
    "    ax1.imshow(x_tile[:,:,0:3])\n",
    "    ax1.set_title('Test Image {}'.format(t_choice))\n",
    "        \n",
    "    ax2.imshow(x_tile[:,:,4])\n",
    "    ax2.set_title('Test DEM {}'.format(t_choice))\n",
    "    \n",
    "    ax3.imshow(y_tile)\n",
    "    ax3.set_title('Test Truth Label {}'.format(t_choice))\n",
    "    \n",
    "    ax4.imshow(y_pred_i)\n",
    "    ax4.set_title('Test Predicted Label {}'.format(t_choice))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VVGe93JRfdX_"
   },
   "source": [
    "PLEASE ANSWER THE QUESTIONS BELOW: What is your analysis of the results from both the quantitative metrics (precision, recall, f1-score) and qualitative visualization? </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2rknP4J-fxmm",
    "outputId": "6a1808d9-dc6f-42c7-c718-266b00877246"
   },
   "outputs": [],
   "source": [
    "ans = '''\n",
    "xxx\n",
    "'''\n",
    "\n",
    "print(ans)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
